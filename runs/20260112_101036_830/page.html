<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Security-Policy" content="default-src 'none'; img-src data:; style-src 'unsafe-inline'; script-src 'unsafe-inline'; connect-src 'self'; base-uri 'none'; form-action 'none';">
  <style>
    body {
      font-family: Arial, sans-serif;
    }
    .error-message {
      color: red;
    }
  </style>
</head>
<body>
  <h1 id="title">Single-Page Web App Plan</h1>
  <p id="description"></p>
  <form id="login-form">
    <label for="username">Username:</label>
    <input type="text" id="username" name="username"><br><br>
    <label for="password">Password:</label>
    <input type="password" id="password" name="password"><br><br>
    <button id="submit-button">Login</button>
  </form>
  <div id="dashboard">
    <h2>Dashboard</h2>
    <p id="dashboard-data"></p>
  </div>
  <script>
    async function generateStory(prompt) {
      const sessionToken = await window.geaRuntimeLLM(prompt);
      document.getElementById('title').textContent = `Your generated story: ${sessionToken}`;
    }

    document.getElementById('submit-button').addEventListener('click', (e) => {
      e.preventDefault();
      const username = document.getElementById('username').value;
      const password = document.getElementById('password').value;
      generateStory(`You are a user with the username ${username} and the password ${password}`);
    });

    window.onload = async () => {
      await generateStory("Start generating your story");
    };
  </script>

<script id="gea-runtime-helper">
(function () {
  if (window.geaRuntimeLLM) return;
  const defaultModel = "llama3.2";
  async function callRuntimeLLM(prompt, options = {}) {
    if (!prompt || typeof prompt !== "string") {
      throw new Error("Prompt must be a non-empty string");
    }
    const model = typeof options.model === 'string' && options.model.trim() ? options.model.trim() : defaultModel;
    const response = await fetch('/api/runtime/llm', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt, model }),
      signal: options.signal
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(error && error.error ? error.error : 'Runtime LLM request failed');
    }
    const data = await response.json().catch(() => ({}));
    return data && data.response ? data.response : '';
  }
  window.geaRuntimeLLM = callRuntimeLLM;
})();
</script>
</body>
</html>