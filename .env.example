HOST=0.0.0.0
PORT=3000

# LLM Provider: "groq" for Groq API, "ollama" for local Ollama
LLM_PROVIDER=groq

# Groq API Key (get one at https://console.groq.com)
GROQ_API_KEY=your_groq_api_key_here

# Default models (use Groq model names when LLM_PROVIDER=groq)
# Popular Groq models: llama-3.1-70b-versatile, llama-3.1-8b-instant, moonshotai/kimi-k2-instruct-0905
PLANNER_MODEL=moonshotai/kimi-k2-instruct-0905
CODER_MODEL=moonshotai/kimi-k2-instruct-0905
RUNTIME_MODEL=llama-3.1-8b-instant

# Available model options (comma-separated, for dropdown)
# When using Groq, models are fetched dynamically from the API
MODEL_OPTIONS=llama-3.1-70b-versatile,llama-3.1-8b-instant,llama-3.3-70b-versatile,mixtral-8x7b-32768

# LLM request timeout in milliseconds
LLM_TIMEOUT_MS=120000
