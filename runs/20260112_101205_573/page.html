<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Security-Policy" content="default-src 'none'; img-src data:; style-src 'unsafe-inline'; script-src 'unsafe-inline'; connect-src 'self'; base-uri 'none'; form-action 'none';">
<style>
body {
  font-family: Arial, sans-serif;
}

.header {
  background-color: #333;
  color: white;
  padding: 10px;
  text-align: center;
}

.nav-menu {
  list-style: none;
  margin: 0;
  padding: 0;
}

.nav-link {
  display: inline-block;
  margin-right: 20px;
  background-color: #333;
  color: white;
  border-radius: 5px;
  cursor: pointer;
}

.footer {
  background-color: #333;
  color: white;
  padding: 10px;
  text-align: center;
}
</style>
<title>Single-Page Web App</title>
</head>
<body>
<header class="header"> Single-Page Web App </header>
<nav class="nav-menu">
<ul>
<li class="nav-link"><a href="#home">Home</a></li>
</ul>
</nav>
<footer class="footer"> Generated with Gea Runtime LLM </footer>

<script>
function generateStory(prompt) {
  const geaRuntimeLLM = await window.geaRuntimeLLM(prompt);
  return geaRuntimeLLM;
}

generateStory("Generate a story based on user prompt")
</script>

<script id="gea-runtime-helper">
(function () {
  if (window.geaRuntimeLLM) return;
  const defaultModel = "llama3.2";
  async function callRuntimeLLM(prompt, options = {}) {
    if (!prompt || typeof prompt !== "string") {
      throw new Error("Prompt must be a non-empty string");
    }
    const model = typeof options.model === 'string' && options.model.trim() ? options.model.trim() : defaultModel;
    const response = await fetch('/api/runtime/llm', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt, model }),
      signal: options.signal
    });
    if (!response.ok) {
      const error = await response.json().catch(() => ({}));
      throw new Error(error && error.error ? error.error : 'Runtime LLM request failed');
    }
    const data = await response.json().catch(() => ({}));
    return data && data.response ? data.response : '';
  }
  window.geaRuntimeLLM = callRuntimeLLM;
})();
</script>
</body>
</html>